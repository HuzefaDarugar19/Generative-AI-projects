# ğŸ“„ HEART HEALTH Q&A Bot with TinyLlama + FAISS

An AI-powered Question Answering bot that can read, understand, and answer questions based on **WHO GUIDELINES** â€” fast and accurate!  
Built with **FAISS** for semantic search, **Sentence Transformers** for embeddings, and **TinyLlama** for local inference.

---

## ğŸš€ Features
- **PDF ingestion** â†’ Reads and splits your PDF content into searchable chunks.
- **FAISS vector search** â†’ Finds the most relevant text sections for your query.
- **TinyLlama responses** â†’ Generates natural, context-based answers.
- **Streamlit web UI** â†’ Easy-to-use, interactive interface.
- **Local & Private** â†’ No external API calls â€” all processing happens locally.

---

## ğŸ›  Tech Stack
- [Streamlit](https://streamlit.io/) â€“ Web app framework
- [FAISS](https://github.com/facebookresearch/faiss) â€“ Vector search
- [Sentence Transformers](https://www.sbert.net/) â€“ Embedding model
- [LangChain](https://www.langchain.com/) â€“ LLM integration
- [Ollama](https://ollama.ai/) â€“ Local TinyLlama inference

---

---

## âš¡ Quick Start

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/HuzefaDarugar19/Generative-AI-projects.git
cd Generative-AI-projects


## ğŸ“‚ Project Structure
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Build the FAISS Index (Run Only Once per PDF Update)
bash : python build_index.py

4ï¸âƒ£ Launch the Streamlit App
bash : streamlit run app.py

ğŸ“Œ Usage
Place your PDFs in the sample_pdfs/ folder (or update the path in build_index.py).

Run build_index.py to process and index them.

Start app.py and open the browser link provided by Streamlit.

Ask questions â€” the bot will respond only using the PDF content.

ğŸ¯ Example
Question:

What are heart disease prevention methods?

Answer:

Eat a balanced diet, exercise regularly, avoid smoking, and manage stress effectively.

ğŸ§  How It Works
Text Extraction â†’ PyPDF2 reads PDF pages.

Chunking â†’ LangChain splits text into overlapping sections.

Embedding â†’ all-MiniLM-L6-v2 converts text into vectors.

Vector Storage â†’ FAISS stores and searches these vectors.

LLM Reasoning â†’ TinyLlama generates answers based on the retrieved chunks.

ğŸ“œ License
This project is licensed under the MIT License â€” free to use and modify.

ğŸ’¡ Future Improvements
PDF upload feature directly in Streamlit UI

Support for multiple embedding models

Option to run with other local LLMs via Ollama

Docker support for easy deployment

â¤ï¸ Acknowledgements
Sentence Transformers

FAISS

LangChain

Ollama

Streamlit

---








